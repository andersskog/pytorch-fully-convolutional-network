{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Networks for Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 50\n",
    "NUM_CLASSES = 3173\n",
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(batch_data, pred):\n",
    "    (imgs, segs, infos) = batch_data\n",
    "    _, preds = torch.max(pred.data.cpu(), dim=1)\n",
    "    valid = (segs >= 0)\n",
    "    acc = 1.0 * torch.sum(valid * (preds == segs)) / (torch.sum(valid) + 1e-10)\n",
    "    return acc, torch.sum(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as torchdata\n",
    "from torchvision import transforms\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "class Dataset(torchdata.Dataset):\n",
    "    def __init__(self, root_folder, image_list, max_sample=-1, is_train=1):\n",
    "        self.root_img = './{}/dataset/images'.format(root_folder)\n",
    "        self.root_seg = './{}/dataset/annotations'.format(root_folder)\n",
    "        self.imgSize = 100\n",
    "        self.segSize = 100\n",
    "        self.is_train = is_train\n",
    "\n",
    "        # mean and std\n",
    "        self.img_transform = transforms.Compose([\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "        self.list_sample = [x.rstrip() for x in open(image_list, 'r')]\n",
    "\n",
    "        if self.is_train:\n",
    "            random.shuffle(self.list_sample)\n",
    "        if max_sample > 0:\n",
    "            self.list_sample = self.list_sample[0:max_sample]\n",
    "        num_sample = len(self.list_sample)\n",
    "        assert num_sample > 0\n",
    "        print('# samples: {}'.format(num_sample))\n",
    "\n",
    "    def _scale_and_crop(self, img, seg, cropSize, is_train):\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "\n",
    "        if is_train:\n",
    "            # random scale\n",
    "            scale = random.random() + 0.5     # 0.5-1.5\n",
    "            scale = max(scale, 1. * cropSize / (min(h, w) - 1))\n",
    "        else:\n",
    "            # scale to crop size\n",
    "            scale = 1. * cropSize / (min(h, w) - 1)\n",
    "\n",
    "        img_scale = imresize(img, scale, interp='bilinear')\n",
    "        seg_scale = imresize(seg, scale, interp='nearest')\n",
    "\n",
    "        h_s, w_s = img_scale.shape[0], img_scale.shape[1]\n",
    "        if is_train:\n",
    "            # random crop\n",
    "            x1 = random.randint(0, w_s - cropSize)\n",
    "            y1 = random.randint(0, h_s - cropSize)\n",
    "        else:\n",
    "            # center crop\n",
    "            x1 = (w_s - cropSize) // 2\n",
    "            y1 = (h_s - cropSize) // 2\n",
    "\n",
    "        img_crop = img_scale[y1: y1 + cropSize, x1: x1 + cropSize, :]\n",
    "        seg_crop = seg_scale[y1: y1 + cropSize, x1: x1 + cropSize]\n",
    "        return img_crop, seg_crop\n",
    "\n",
    "    def _flip(self, img, seg):\n",
    "        img_flip = img[:, ::-1, :]\n",
    "        seg_flip = seg[:, ::-1]\n",
    "        return img_flip, seg_flip\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_basename = self.list_sample[index]\n",
    "        path_img = os.path.join(self.root_img, img_basename)\n",
    "        path_seg = os.path.join(self.root_seg,\n",
    "                                img_basename.replace('.jpg', '.png'))\n",
    "\n",
    "        assert os.path.exists(path_img), '[{}] does not exist'.format(path_img)\n",
    "        assert os.path.exists(path_seg), '[{}] does not exist'.format(path_seg)\n",
    "\n",
    "        # load image and label\n",
    "        try:\n",
    "            img = imread(path_img, mode='RGB')\n",
    "            seg = imread(path_seg)\n",
    "            assert(img.ndim == 3)\n",
    "            assert(seg.ndim == 2)\n",
    "            assert(img.shape[0] == seg.shape[0])\n",
    "            assert(img.shape[1] == seg.shape[1])\n",
    "\n",
    "            # random scale, crop, flip\n",
    "            if self.imgSize > 0:\n",
    "                img, seg = self._scale_and_crop(img, seg,\n",
    "                                                self.imgSize, self.is_train)\n",
    "                if random.choice([-1, 1]) > 0:\n",
    "                    img, seg = self._flip(img, seg)\n",
    "\n",
    "            # image to float\n",
    "            img = img.astype(np.float32) / 255.\n",
    "            img = img.transpose((2, 0, 1))\n",
    "\n",
    "            if self.segSize > 0:\n",
    "                seg = imresize(seg, (self.segSize, self.segSize),\n",
    "                               interp='nearest')\n",
    "\n",
    "            # label to int from -1 to 149\n",
    "            seg = seg.astype(np.int) - 1\n",
    "\n",
    "            # to torch tensor\n",
    "            image = torch.from_numpy(img)\n",
    "            segmentation = torch.from_numpy(seg)\n",
    "        except Exception as e:\n",
    "            print('Failed loading image/segmentation [{}]: {}'\n",
    "                  .format(path_img, e))\n",
    "            # dummy data\n",
    "            image = torch.zeros(3, self.imgSize, self.imgSize)\n",
    "            segmentation = -1 * torch.ones(self.segSize, self.segSize).long()\n",
    "            return image, segmentation, img_basename\n",
    "\n",
    "        # substracted by mean and divided by std\n",
    "        image = self.img_transform(image)\n",
    "\n",
    "        return image, segmentation, img_basename\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and Loader\n",
    "def load_dataset(train_list, val_list, root_folder):\n",
    "    dataset_train = Dataset(root_folder, '{}/{}'.format(root_folder, train_list), is_train=1)\n",
    "    dataset_val = Dataset(root_folder, '{}/{}'.format(root_folder, val_list), is_train=0)\n",
    "    loader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        drop_last=True)\n",
    "    loader_val = torch.utils.data.DataLoader(\n",
    "        dataset_val,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=1,\n",
    "        drop_last=True) \n",
    "    return loader_train, loader_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch_data, model, optimizer, criterion, train=True, print_accuracy=False):\n",
    "    (imgs, segs, infos) = batch_data\n",
    "\n",
    "    # feed input data\n",
    "    input_img = Variable(imgs, volatile=not is_train).cuda() if USE_CUDA else Variable(imgs, volatile=not train)\n",
    "    label_seg = Variable(segs, volatile=not is_train).cuda() if USE_CUDA else Variable(segs, volatile=not train)\n",
    "\n",
    "    # forward pass\n",
    "    pred = model(input_img)\n",
    "    err = criterion(pred, label_seg)\n",
    "\n",
    "    # Backward\n",
    "    if train:\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if print_accuracy:\n",
    "        print('Accuracy: {}'.format(accuracy(batch_data, pred)))\n",
    "    \n",
    "    return err.data[0]\n",
    "   \n",
    "def train(train_loader, val_loader, model, optimizer, criterion):\n",
    "    print('start training')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print('epoch')\n",
    "        timestamp1 = time.time()\n",
    "        training_loss = 0\n",
    "        val_loss = 0\n",
    "        for index, batch_data in enumerate(train_loader):\n",
    "            print('step')\n",
    "            print_accuracy = False\n",
    "            if index % 100:\n",
    "                print_accuracy = True\n",
    "            training_loss += train_step(batch_data, model, optimizer, criterion, train=True, print_accuracy = True)\n",
    "        for index, batch_data in enumerate(val_loader):\n",
    "            val_loss += train_step(batch_data, model, optimizer, criterion, train=False)\n",
    "        timestamp2 = time.time()\n",
    "        train_losses.append(training_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print('\\nEpoch: {} | TRAINING Loss: {} | TESTING Loss: {} | Time: {}\\n'.format(\n",
    "            epoch_num + 1, training_loss, val_loss, timestamp2 - timestamp1))\n",
    "        return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_FCN_8(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VGG_FCN_8, self).__init__()\n",
    "        self.features = nn.Sequential(*list(torchvision.models.vgg16(pretrained=True).features))\n",
    "        self.upsampler_x32_sequence = nn.Sequential(nn.Conv2d(512, 4096, kernel_size=7),\n",
    "                                                    nn.ReLU(True),\n",
    "                                                    nn.Dropout(),\n",
    "                                                    nn.Conv2d(4096, 4096, kernel_size=1),\n",
    "                                                    nn.ReLU(True),\n",
    "                                                    nn.Dropout(),\n",
    "                                                    nn.Conv2d(4096, NUM_CLASSES, kernel_size=1)\n",
    "                                                   )\n",
    "        self.upsampler_x32 = nn.ConvTranspose2d(NUM_CLASSES, NUM_CLASSES, kernel_size=4, stride=2, bias=False)\n",
    "        self.upsampler_x16_sequence = nn.Sequential(nn.Conv2d(512, NUM_CLASSES, kernel_size=1))\n",
    "        self.upsampler_x16 = nn.ConvTranspose2d(NUM_CLASSES, NUM_CLASSES,  kernel_size=4, stride=2, bias=False)                                    \n",
    "        self.upsampler_x8_sequence = nn.Sequential(nn.Conv2d(256, NUM_CLASSES, kernel_size=1))\n",
    "        self.upsampler_x8 = nn.ConvTranspose2d(NUM_CLASSES, NUM_CLASSES, kernel_size=16, stride=8, bias=False)\n",
    "        \n",
    "        self.features[0].padding = (100, 100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_size = x.size()\n",
    "        output = x\n",
    "        for i in range(17):\n",
    "            output = self.features[i](output)\n",
    "        upsample_x8 = self.upsampler_x8_sequence(0.0001 * output)\n",
    "        for i in range(17, 24):\n",
    "            output = self.features[i](output)\n",
    "        upsample_x16 = self.upsampler_x16_sequence(0.01 * output)\n",
    "        for i in range(24, 31):\n",
    "            output = self.features[i](output)\n",
    "        upsample_x32 = self.upsampler_x32_sequence(output)\n",
    "        upscore_x32 = self.upsampler_x32(upsample_x32)\n",
    "        upscore_x16 = self.upsampler_x16(upsample_x16[:, :, 5: (5 + upscore_x32.size()[2]), 5: (5 + upscore_x32.size()[3])] + upscore_x32) \n",
    "        upscore_x8 = self.upsampler_x8(upsample_x8[:, :, 9: (9 + upscore_x16.size()[2]), 9: (9 + upscore_x16.size()[3])] + upscore_x16)\n",
    "        upscore_x8 = upscore_x8[:, :, 31: (31 + x_size[2]), 31: (31 + x_size[3])].contiguous()\n",
    "        return upscore_x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    model_conv = VGG_FCN_8()\n",
    "    # freeze vgg params\n",
    "    for param in model_conv.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Parameters of newly constructed modules have requires_grad=True by default\n",
    "    if USE_CUDA:\n",
    "        model_conv = model_conv.cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_conv = torch.optim.SGD(filter(lambda p: p.requires_grad,  model_conv.parameters()), lr=1e-3, momentum=0.9)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "    return model_conv, optimizer_conv, criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples: 20210\n",
      "# samples: 2000\n",
      "Dataset loaded.\n",
      "Model initialized, starting training...\n",
      "\n",
      "start training\n",
      "epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:76: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:77: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:43: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:96: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step\n"
     ]
    }
   ],
   "source": [
    "train_list = 'train.txt'\n",
    "val_list = 'val.txt'\n",
    "root_folder = 'data'\n",
    "loader_train, loader_val = load_dataset(train_list, val_list, root_folder)\n",
    "print('Dataset loaded.')\n",
    "model, optimizer, criterion = initialize_model()\n",
    "print('Model initialized, starting training...\\n')\n",
    "train(loader_train, loader_val, model, optimizer, criterion)\n",
    "print('Training has ended.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
